import pandas as pd
import numpy as np
import pickle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder
from xgboost import XGBClassifier
from sklearn.multioutput import MultiOutputClassifier
from sklearn.metrics import accuracy_score, classification_report

# 1Ô∏è‚É£ ƒê·ªçc d·ªØ li·ªáu
data = pd.read_csv('D:/final_4796_hanoi_hcm_updated.csv')

# 2Ô∏è‚É£ Gi·ªØ l·∫°i c√°c thu·ªôc t√≠nh c·∫ßn thi·∫øt
features = ["Age", "Gender", "Category", "Season", "Review Rating",
            "Payment Method", "Preferred Payment Method", "Previous Purchases",
            "Frequency of Purchases", "Purchase Amount (VND)"]  # ƒê·ªïi t√™n c·ªôt

targets = ["Item Purchased", "Color"]  # D·ª± ƒëo√°n s·∫£n ph·∫©m + m√†u

df = data[features + targets].dropna()

# Chuy·ªÉn ƒë·ªïi c·ªôt 'Frequency of Purchases' th√†nh s·ªë
purchase_freq_map = {"Weekly": 1, "Bi-Weekly": 2, "Monthly": 4, "Quarterly": 12, "Annually": 52}
df["Frequency of Purchases"] = df["Frequency of Purchases"].map(purchase_freq_map)

# Lo·∫°i b·ªè c√°c gi√° tr·ªã kh√¥ng h·ª£p l·ªá
df = df.dropna()

# 3Ô∏è‚É£ Chia t·∫≠p d·ªØ li·ªáu th√†nh Train - Validation - Test
train_data, test_data = train_test_split(df, test_size=0.3, random_state=42)
train_data, val_data = train_test_split(train_data, test_size=0.3, random_state=42)

# 4Ô∏è‚É£ M√£ h√≥a bi·∫øn ph√¢n lo·∫°i
categorical_features = ["Gender", "Category", "Season", "Payment Method", "Preferred Payment Method"]
ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
ohe.fit(train_data[categorical_features])

X_train_cat = ohe.transform(train_data[categorical_features])
X_val_cat = ohe.transform(val_data[categorical_features])
X_test_cat = ohe.transform(test_data[categorical_features])

# 5Ô∏è‚É£ Chu·∫©n h√≥a d·ªØ li·ªáu s·ªë
numerical_features = ["Age", "Review Rating", "Previous Purchases",
                      "Frequency of Purchases", "Purchase Amount (VND)"]
scaler = StandardScaler()
scaler.fit(train_data[numerical_features])

X_train_num = scaler.transform(train_data[numerical_features])
X_val_num = scaler.transform(val_data[numerical_features])
X_test_num = scaler.transform(test_data[numerical_features])

# 6Ô∏è‚É£ K·∫øt h·ª£p l·∫°i th√†nh d·ªØ li·ªáu ƒë·∫ßu v√†o
X_train = np.hstack([X_train_cat, X_train_num])
X_val = np.hstack([X_val_cat, X_val_num])
X_test = np.hstack([X_test_cat, X_test_num])

y_train = train_data[targets]
y_val = val_data[targets]
y_test = test_data[targets]

# 7Ô∏è‚É£ M√£ h√≥a nh√£n ƒë·∫ßu ra
label_encoders = {}
y_train_encoded = y_train.copy()
y_val_encoded = y_val.copy()
y_test_encoded = y_test.copy()

for col in targets:
    le = LabelEncoder()
    y_train_encoded[col] = le.fit_transform(y_train[col])
    y_val_encoded[col] = le.transform(y_val[col])
    y_test_encoded[col] = le.transform(y_test[col])
    label_encoders[col] = le

# 8Ô∏è‚É£ Hu·∫•n luy·ªán m√¥ h√¨nh XGBoost v·ªõi MultiOutputClassifier (c·∫£i ti·∫øn ch·ªëng overfitting)
xgb_base = XGBClassifier(
    n_estimators=80,  # Gi·∫£m s·ªë l∆∞·ª£ng c√¢y ƒë·ªÉ tr√°nh overfitting
    max_depth=6,  # Gi·∫£m ƒë·ªô s√¢u c·ªßa c√¢y
    learning_rate=0.1,
    subsample=0.9,  # TƒÉng dropout tr√™n t·∫≠p d·ªØ li·ªáu train
    colsample_bytree=0.7,  # Gi·∫£m s·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng s·ª≠ d·ª•ng cho m·ªói c√¢y
    reg_alpha=0.5,  # Th√™m regularization L1
    reg_lambda=1.0,  # Th√™m regularization L2
    booster='dart',  # D√πng DART ƒë·ªÉ dropout c√°c c√¢y kh√¥ng quan tr·ªçng
    rate_drop=0.2,  # X√°c su·∫•t dropout c√¢y
    skip_drop=0.5,  # X√°c su·∫•t b·ªè qua c√¢y khi train
    random_state=42
)
xgb_model = MultiOutputClassifier(xgb_base)
xgb_model.fit(X_train, y_train_encoded)

# 9Ô∏è‚É£ L∆∞u m√¥ h√¨nh v√† c√°c b·ªô m√£ h√≥a
to_save = {'model': xgb_model, 'ohe': ohe, 'scaler': scaler, 'label_encoders': label_encoders}
with open('xgb_model.pkl', 'wb') as f:
    pickle.dump(to_save, f)

# üîü D·ª± ƒëo√°n v√† ƒë√°nh gi√° m√¥ h√¨nh
y_pred_encoded = xgb_model.predict(X_val)

for i, target in enumerate(targets):
    print(f"Accuracy for {target}: {accuracy_score(y_val_encoded[target], y_pred_encoded[:, i]):.4f}")
    print(classification_report(y_val_encoded[target], y_pred_encoded[:, i], zero_division=1))